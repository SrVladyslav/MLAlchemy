{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ea3981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "response = requests.get(url)\n",
    "text = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5373fd05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6383a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n",
      "1115394\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5e0e164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Set of characters:\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "> Vocab Size: 65\n"
     ]
    }
   ],
   "source": [
    "# Obtaining all the set of characters that are ocurring in the text\n",
    "# The vocabulary are the possible characters that the model can see or emit\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"> Set of characters:\"+''.join(chars))\n",
    "print(\"> Vocab Size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d2ed3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 27, 24, 13]\n",
      "HOLA\n"
     ]
    }
   ],
   "source": [
    "# Strategy to tokenize the text: convert the RAW text to some sequence of integers\n",
    "# according to some vocabulary of elements\n",
    "# Mapping the characters to integers, so we can obtain a encoder and decoder\n",
    "# Character level\n",
    "\n",
    "# Puedes tener una secuencia muy larga de tokens con vocabulario pequeño o\n",
    "# o pequeñas secuencias de enteros con grandes vocabularios, \n",
    "# -- > In the practise, peopl uses subword encodings\n",
    "stoi = { character:i for i,character in enumerate(chars)}\n",
    "itos = {i:character for i,character in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [ stoi[c] for c in s ]\n",
    "decode = lambda s: ''.join([itos[i] for i in s])\n",
    "\n",
    "print(encode(\"HOLA\"))\n",
    "print(decode(encode(\"HOLA\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66a04619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Thxt\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer used in GPT\n",
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# To get the tokeniser corresponding to a specific model in the OpenAI API:\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "print(enc.decode([23,666,2302]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68da0fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "# To keep it simple, we will be using the char lvl tokenizer, lets use torch\n",
    "import torch\n",
    "\n",
    "# Encoding the data into tensors\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c39dde08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtraining the training and validation set of data \n",
    "# Our split will be 90% for training set and 10% for validation \n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "valid_data = data[n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19a761e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can't fit all the dataset into the model, so we need to create \n",
    "# minor batches for it, chunks of data, max length foir a chunk\n",
    "block_size = 8 \n",
    "'''\n",
    "This string has actually multiple examples packed into it, because all of this characters \n",
    "follow each other. In this chunk of 9 chars, the're actually 8 individual examples \n",
    "packed in there\n",
    "'''\n",
    "train_data[:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cac8ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([18]) the target is 47\n",
      "When input is tensor([18, 47]) the target is 56\n",
      "When input is tensor([18, 47, 56]) the target is 57\n",
      "When input is tensor([18, 47, 56, 57]) the target is 58\n",
      "When input is tensor([18, 47, 56, 57, 58]) the target is 1\n",
      "When input is tensor([18, 47, 56, 57, 58,  1]) the target is 15\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15]) the target is 47\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is 58\n"
     ]
    }
   ],
   "source": [
    "# Basically in the example before we have all these examples\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1] # Targets for each position\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1] # all characters up to t anmd including t\n",
    "    target = y[t]\n",
    "    print(f\"When input is {context} the target is {target}\")\n",
    "\n",
    "# We do that to make transforme to seee the context of each of these words,\n",
    "# For the first word,from the near neightbour to the end of them, so \n",
    "# all the way from as little as one to as block size.\n",
    "# So when we sampling, we can sample from as little as one character\n",
    "# and the transformers knows how to predict the next character in context of one, \n",
    "# and then to to size of block size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8989ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "Tragets: \n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# When fidding to the GPU, we will have many batches of chunks of text, because the GPU\n",
    "# -> That's for take GPU busy, they're very good on parallel processing of data\n",
    "# We want to proces multipole chuks, all at the same time, but they're processed completely\n",
    "# independently and do not talk with each other\n",
    "\n",
    "# Generating the batch of data\n",
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # The independent sequences that we will process in parallel\n",
    "block_size = 8 # The maximum context length for predictions\n",
    "\n",
    "def get_batch(split):\n",
    "    # Generates a small batch of data of inputs x and targets y\n",
    "    data = train_data if split =='train' else valid_data\n",
    "    # Size between zero and random block size\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y \n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print(\"Inputs: \")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"Tragets: \")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('-'*10)\n",
    "\n",
    "for b in range(batch_size): # Batch dimension\n",
    "    for t in range(block_size): # Time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        # print(f\"When input is {context.tolist()} the targtet is: {target}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ff313c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n"
     ]
    }
   ],
   "source": [
    "print(xb)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2efff74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F \n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()  \n",
    "        # Each token directly reads off the logits for the next token from a lookup table \n",
    "        # This creates a token embedding table of size: vocab_size x vocab_size\n",
    "        # bawsically is a tensor of vocab_size x vocab_size\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are both (B,T) tensor integers \n",
    "        logits = self.token_embedding_table(idx) # (Batch=4, Time=8, Channel=65) tensor\n",
    "        # Channel and vocab size are the same, The logits \n",
    "        # are basically the scores for the next character sequence\n",
    "        # Here we predict what comes next just on individual identity of this single token\n",
    "        # This tokens do not see any context yet.\n",
    "        # ------------------------------\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None # Will return logits in (B, T, C) form and None\n",
    "        else:\n",
    "            # Obtaining the loss, negative log likelihood, between preddictions and targets \n",
    "            # Quality of logits respect targets, we have the identity of the next char, so how \n",
    "            # well we can predict it.\n",
    "            # We also need to reshape the logits B,T,C to B,C,T in order to fit torch function\n",
    "            B,T,C = logits.shape \n",
    "\n",
    "            # We stretch the logits into 2 dimensional tensor to conform better pythorch def\n",
    "            # hERE we can evaluate the quality of the model on some data\n",
    "            logits = logits.view(B*T, C) # Becomes (B, C)\n",
    "            targets = targets.view(B*T) # -1 is also valid\n",
    "            loss = F.cross_entropy(logits, targets) # -ln(1/65) == 4.174 should be the ideal loss\n",
    "\n",
    "        return logits, loss \n",
    "    \n",
    "    #Generate the model \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Get the predictions by calling the forward function \n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step \n",
    "            logits = logits[:, -1, :] # Becomes (B, C)\n",
    "            # Obtaining the probabilities by applying the softmax \n",
    "            probs = F.softmax(logits, dim=1) # (B, C)\n",
    "            # Sample from the distribution to obtain new characters in the sequence \n",
    "            idx_next = torch.multinomial(probs, num_samples= 1) # (B, 1)\n",
    "            # Append sampled index to the current sequence, \n",
    "            # Concatenating along the first dim, which is the Time dimension (T=8)\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "# As we work with batches, we use the index 0 to unplug the 0 batch\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85c6ca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model, let's create an optimizer \n",
    "# Using PyTorch optimizer\n",
    "# Normally you will use 1e-3 o 1e-4 for networks, \n",
    "# but for smaller ones you can use bigger ones\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a37f2c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.704006195068359\n",
      "3.7031264305114746\n",
      "3.1371781826019287\n",
      "2.776794672012329\n",
      "2.5844571590423584\n",
      "2.5105180740356445\n",
      "2.531585931777954\n",
      "2.504757881164551\n",
      "2.4696712493896484\n",
      "2.4838879108428955\n"
     ]
    }
   ],
   "source": [
    "# training the model \n",
    "batch_size = 32 # 4 Is too small\n",
    "STEPS_RANGE = 10000\n",
    "\n",
    "for steps in range(STEPS_RANGE):\n",
    "    # Sample batch data \n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # Evaluating the loss \n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True) # Zeroing all the gradients from the previous step\n",
    "    loss.backward() # Getting the gradients for all the parameters\n",
    "    optimizer.step() # Using those gradients to update the parameters\n",
    "\n",
    "    if steps % (STEPS_RANGE / 10) == 0:    \n",
    "        print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b22c3b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iyoteng h hasbe pave pirance\n",
      "Rie hicomyonthar's\n",
      "Plinseard ith henoure wounonthioneir thondy, y heltieiengerofo'dsssit ey\n",
      "KIN d pe wither vouprrouthercc.\n",
      "hathe; d!\n",
      "My hind tt hinig t ouchos tes; st yo hind wotte grotonear 'so it t jod weancotha:\n",
      "h hay\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=250)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8750498c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0730854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1236\n"
     ]
    }
   ],
   "source": [
    "f = {'train':1.12355678}\n",
    "print(f\"{f['train']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe5239b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44699a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[58,  7, 57, 43, 56, 60, 39, 52],\n",
      "        [46, 39, 50, 50,  1, 52, 53, 58],\n",
      "        [ 0, 31, 58, 39, 52, 42, 57,  1],\n",
      "        [58, 46, 63,  1, 46, 53, 56, 57],\n",
      "        [50, 47,  1, 50, 47, 49, 43,  1],\n",
      "        [41, 63,  6,  1, 50, 47, 49, 43],\n",
      "        [ 8,  1, 25, 63,  1, 61, 53, 51],\n",
      "        [24, 33, 15, 21, 27, 10,  0, 19],\n",
      "        [60, 39, 52, 58,  7, 51, 39, 47],\n",
      "        [53, 53, 42,  1, 26, 53, 56, 44],\n",
      "        [44,  1, 63, 53, 59,  1, 53, 52],\n",
      "        [30, 31, 10,  0, 13, 52, 42,  1],\n",
      "        [ 2,  1, 57, 43, 56, 47, 53, 59],\n",
      "        [46, 39, 56, 45, 43,  1, 63, 43],\n",
      "        [43,  6,  0, 14, 63,  1, 41, 47],\n",
      "        [46, 58, 43, 42,  1, 50, 47, 49],\n",
      "        [ 0, 35, 47, 50, 58,  1, 58, 46],\n",
      "        [30, 27, 25, 17, 27, 10,  0, 13],\n",
      "        [53, 59, 56,  1, 45, 53, 53, 42],\n",
      "        [57, 46, 39, 50, 50,  1, 49, 47],\n",
      "        [11,  1, 39, 52, 42,  1, 52, 53],\n",
      "        [58, 46, 43, 56,  1, 42, 39, 63],\n",
      "        [10,  1, 21,  1, 61, 53, 59, 50],\n",
      "        [63, 57, 43, 50, 44,  0, 20, 53],\n",
      "        [52, 53, 59, 56,  1, 50, 39, 47],\n",
      "        [42,  1, 41, 39, 59, 57, 43, 57],\n",
      "        [44, 47, 52, 42,  1, 58, 46, 43],\n",
      "        [39,  1, 45, 59, 43, 57, 58,  0],\n",
      "        [46, 39, 51,  6,  1, 57, 43, 39],\n",
      "        [63, 43, 58,  1, 59, 54, 53, 52],\n",
      "        [45, 46, 58, 52, 47, 52, 45,  1],\n",
      "        [60, 43,  1, 40, 43, 43, 52,  1]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[32]' is invalid for input of size 256",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(yb)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43myb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(xb)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[32]' is invalid for input of size 256"
     ]
    }
   ],
   "source": [
    "print(yb)\n",
    "print(yb.view(4*8))\n",
    "print(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13b0989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39,  1],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1,  2],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46,  3],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39,  4]])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39,  1,  1],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1,  2,  2],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46,  3,  3],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39,  4,  4]])\n"
     ]
    }
   ],
   "source": [
    "f = torch.tensor([\n",
    "        [43, 58,  5, 57,  1, 46, 43, 39],\n",
    "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
    "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
    "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
    "print(f)\n",
    "f = torch.cat((f, torch.tensor([[1],[2],[3],[4]])), dim=1)\n",
    "print(f)\n",
    "f = torch.cat((f, torch.tensor([[1],[2],[3],[4]])), dim=1)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7d2aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51accadd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be55f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2618fece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ac2112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2349bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1eb5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(ids):\n",
    "    \"\"\"\n",
    "        Given a list of integers, return a dictionary of counts of consecutive pairs\n",
    "        Example: [1, 2, 3, 1, 2] -> {(1, 2): 2, (2, 3): 1, (3, 1): 1}\n",
    "    \"\"\"\n",
    "    counts = {}\n",
    "    for pair in zip(ids, ids[1:]): # iterate consecutive elements\n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a9f365-5778-4630-afeb-f3f0b5ea18f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72, 101, 108, 108, 111, 32, 119, 111, 114, 108, 100]\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello world\"\n",
    "\n",
    "# Text to bytes with utf8\n",
    "ids = list(text.encode('utf-8'))\n",
    "print(ids)\n",
    "merges = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a84a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(72, 101): 1, (101, 108): 1, (108, 108): 1, (108, 111): 1, (111, 32): 1, (32, 119): 1, (119, 111): 1, (111, 114): 1, (114, 108): 1, (108, 100): 1}\n"
     ]
    }
   ],
   "source": [
    "# Find the pair with the lowest merge index\n",
    "while len(ids) >=2:\n",
    "    # Obtaining the pairs with the lowest merge inputs \n",
    "    stats = get_stats(ids)\n",
    "    print(stats)\n",
    "    # pair = min(stats, key= lambda p: self.merges.get(p))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc621915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
