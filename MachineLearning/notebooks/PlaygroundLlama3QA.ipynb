{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\srvla\\OneDrive\\Escritorio\\github\\MLAlchemy\\.env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "groqAPIKey = \"<YOUR_API_KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola! Sí, hablo español. Como asistente de programación en Python, estoy aquí para ayudarte en ambos cursos: \"Introduction to Python\" y \"Advanced Python with ML\".\n",
      "\n",
      "Si tienes una pregunta, no dudes en preguntar. Estoy aquí para ayudarte a comprender mejor los conceptos de Python y como aplicarlos en tus proyectos. ¡Vamos a empezar! ¿Qué necesitas ayuda con en el curso que has elegido?\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=groqAPIKey\n",
    ")\n",
    "\n",
    "instruction = \"Please give a full and complete answer for the question.\"\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        # Set an optional system message. This sets the behavior of the\n",
    "        # assistant and can be used to provide specific instructions for\n",
    "        # how it should behave throughout the conversation.\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant specialized in Python programming. Please, give a short and concise answer to the question. Yopu should work with this context and info: You are an assistant in a web that is a open academy of coding in python that has 2 courses, one is an 'Introduction to Python' that contains all about Python programming, and the other is 'Advanced python with ML' that contains all about transformers with PyTorch, you should answer the regarding questions to this courses\",\n",
    "        },\n",
    "        # Set a user message for the assistant to respond to.\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": instruction + \"Hablas español?\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    "    max_tokens=100,\n",
    ")\n",
    "MODEL = 'llama3-70b-8192'\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La pizza italiana tiene un precio base de 8,70€. Si le agregas jamón como ingrediente extra,pagarías 0.60€ más, ya que se trata de una pizza mediana. El total sería de 9,30€. ¿Quieres pedir la pizza o prefieres una pregunta adicional?\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "context = ''' \n",
    "    Tu eres un vendedor virtual de una pizzeria. Tienes que acordarte del contexto y la información de la pizzería que es la siguiente:\n",
    "    \n",
    "    1) El numero de telefono para pedir es \"961858625\", trabajan de \"martes a domingo\" desde las \"18:30\" hasta \"23:00\", solo se puede recoger en el local.\n",
    "    2) Su catálogo de pizzas y su contenido junto a los precios es el siguiente, te los dejo en formato - Nombre: Ingredientes > precio pizza mediana > precio pizza grande en Euros:\n",
    "    - Tropical: Tomate, Mozzarella, York y Piña > 8,70  > €17,40 \n",
    "    - ItalianaCherry: Mozzarella, York, Calabacín Aliñado, Rucula y Virutas de Parmesano > 10,50 > 21,00 \n",
    "    - SicilianaTomate: Mozzarella, Anchoas, Atún y Alcaparras > 9,30 > 18,60\n",
    "    - Porca VaccaTomate: Mozzarella, York, Frankfurt y Queso Azul > 9,30 > 18,60\n",
    "    3) Una vez pidas la pizza, deberás esperar en lo medio unos 15min hasta que se cocine.\n",
    "    4) Tambien hay una posibilidad de añadir ingredientes extras a tu pizza, por cada ingrediente deberias pagar 0.60€ en una pizza mediana y 1.20€ en una pizza grande. Los ingredientes extras disponibles son: \n",
    "    Salsa Barbacoa, Extra Mozzarella, Alparras, Champiñones, Carne, Alcachofas, Pepperoni, Aceitunas Negras, Pimiento, Queso Azul, Cebolla, Queso Emmental, Chorizo, Jamon York, Bacon, Huevo, Salmón, Atún, Anchoas, Piña, Nata, Salami, Requesón, Frankfurt, Parmesano, Gambas, Pollo, Maiz, Queso de Cabra, Pimientos, Cebolla Asada, Cherry\n",
    "\n",
    "'''\n",
    "\n",
    "client = Groq(\n",
    "    api_key=groqAPIKey\n",
    ")\n",
    "\n",
    "instruction = 'Tienes que responder con una respuesta corta y directa en \"Español\", ya si piden más detalles, pues das mas detalles.'\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        # Set an optional system message. This sets the behavior of the\n",
    "        # assistant and can be used to provide specific instructions for\n",
    "        # how it should behave throughout the conversation.\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": context,\n",
    "        },\n",
    "        # Set a user message for the assistant to respond to.\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": instruction + \"Hola, quiero una pizza mediana italiana con extra de Jamon, cuanto me costaria?\",\n",
    "        }\n",
    "    ],\n",
    "    # model=\"llama3-70b-8192\",\n",
    "    model=\"llama3-8b-8192\",\n",
    "    max_tokens=500,\n",
    ")\n",
    "MODEL = 'llama3-70b-8192'\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "class CommerceQABot:\n",
    "    def __init__(self, context, instruction, API_KEY, model_name=\"llama3-8b-8192\", max_tokens=500):\n",
    "        self.model_name = model_name\n",
    "        self.context = context\n",
    "        self.instruction = instruction\n",
    "        self.API_KEY = API_KEY\n",
    "        \n",
    "        self.client = Groq(api_key=API_KEY)\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"Model: {self.model_name}, Context: {self.context}, Instruction: {self.instruction}\"\n",
    "    \n",
    "    def get_answer(self, question, previous_answer=\"\"):\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                # Set an optional system message. This sets the behavior of the\n",
    "                # assistant and can be used to provide specific instructions for\n",
    "                # how it should behave throughout the conversation.\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": self.context,\n",
    "                },\n",
    "                # Set a user message for the assistant to respond to.\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": instruction + question,\n",
    "                },\n",
    "                # The previous answer given by the LLM\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": previous_answer,\n",
    "                }\n",
    "            ],\n",
    "            # model=\"llama3-70b-8192\",\n",
    "            model=self.model_name,\n",
    "            max_tokens= self.max_tokens,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = 'Tienes que responder con una respuesta corta y directa en \"Español\", ya si piden más detalles, pues das mas detalles.'\n",
    "\n",
    "context = ''' \n",
    "    Tu eres un vendedor virtual de una pizzeria. Tienes que acordarte del contexto y la información de la pizzería que es la siguiente:\n",
    "    \n",
    "    1) El numero de telefono para pedir es \"961858625\", trabajan de \"martes a domingo\" desde las \"18:30\" hasta \"23:00\", solo se puede recoger en el local.\n",
    "    2) Su catálogo de pizzas y su contenido junto a los precios es el siguiente, te los dejo en formato - Nombre: Ingredientes > precio pizza mediana > precio pizza grande en Euros:\n",
    "    - Tropical: Tomate, Mozzarella, York y Piña > 8,70  > €17,40 \n",
    "    - ItalianaCherry: Mozzarella, York, Calabacín Aliñado, Rucula y Virutas de Parmesano > 10,50 > 21,00 \n",
    "    - SicilianaTomate: Mozzarella, Anchoas, Atún y Alcaparras > 9,30 > 18,60\n",
    "    - Porca VaccaTomate: Mozzarella, York, Frankfurt y Queso Azul > 9,30 > 18,60\n",
    "    3) Una vez pidas la pizza, deberás esperar en lo medio unos 15min hasta que se cocine.\n",
    "    4) Tambien hay una posibilidad de añadir ingredientes extras a tu pizza, por cada ingrediente deberias pagar 0.60€ en una pizza mediana y 1.20€ en una pizza grande. Los ingredientes extras disponibles son: \n",
    "    Salsa Barbacoa, Extra Mozzarella, Alparras, Champiñones, Carne, Alcachofas, Pepperoni, Aceitunas Negras, Pimiento, Queso Azul, Cebolla, Queso Emmental, Chorizo, Jamon York, Bacon, Huevo, Salmón, Atún, Anchoas, Piña, Nata, Salami, Requesón, Frankfurt, Parmesano, Gambas, Pollo, Maiz, Queso de Cabra, Pimientos, Cebolla Asada, Cherry\n",
    "'''\n",
    "\n",
    "bot = CommerceQABot(instruction=instruction, context=context, API_KEY=groqAPIKey)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
